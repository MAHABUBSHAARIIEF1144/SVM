{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a09c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0     0.0  \n",
      "1     0.0  \n",
      "2     0.0  \n",
      "3     0.0  \n",
      "4     0.0  \n",
      "sepal length (cm)    0\n",
      "sepal width (cm)     0\n",
      "petal length (cm)    0\n",
      "petal width (cm)     0\n",
      "target               0\n",
      "dtype: int64\n",
      "0.0    50\n",
      "1.0    50\n",
      "2.0    50\n",
      "Name: target, dtype: int64\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -1.473937          1.203658          -1.562535         -1.312603\n",
      "1          -0.133071          2.992376          -1.276006         -1.045633\n",
      "2           1.085898          0.085709           0.385858          0.289218\n",
      "3          -1.230143          0.756479          -1.218701         -1.312603\n",
      "4          -1.717731          0.309299          -1.390618         -1.312603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris_data = load_iris()\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "iris_df = pd.DataFrame(data= np.c_[iris_data['data'], iris_data['target']],\n",
    "                       columns= iris_data['feature_names'] + ['target'])\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(iris_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(iris_df.isnull().sum())\n",
    "\n",
    "# Check the distribution of target classes\n",
    "print(iris_df['target'].value_counts())\n",
    "\n",
    "# Splitting features and target variable\n",
    "X = iris_df.drop('target', axis=1)\n",
    "y = iris_df['target']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Encoding categorical variable (target variable)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Display the first few rows of the scaled features\n",
    "print(pd.DataFrame(X_train_scaled, columns=X.columns).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615309e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear, Accuracy: 0.9666666666666667\n",
      "Kernel: rbf, Accuracy: 1.0\n",
      "Kernel: poly, Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a function to train and evaluate SVM models\n",
    "def train_and_evaluate_svm(kernel, C=1.0, gamma='scale'):\n",
    "    # Initialize the SVM classifier\n",
    "    svm_classifier = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    \n",
    "    # Train the SVM classifier\n",
    "    svm_classifier.fit(X_train_scaled, y_train_encoded)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = svm_classifier.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# List of kernels to try\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# Experiment with different kernels and parameters\n",
    "for kernel in kernels:\n",
    "    accuracy = train_and_evaluate_svm(kernel)\n",
    "    print(f'Kernel: {kernel}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d3c08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear, Cross-Validation Accuracy: 0.95\n",
      "Kernel: rbf, Cross-Validation Accuracy: 0.95\n",
      "Kernel: poly, Cross-Validation Accuracy: 0.9416666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k_folds = 5\n",
    "\n",
    "# Initialize KFold object with shuffling\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# List to store cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "for kernel in kernels:\n",
    "    svm_classifier = SVC(kernel=kernel)\n",
    "    scores = cross_val_score(svm_classifier, X_train_scaled, y_train_encoded, cv=kf, scoring='accuracy')\n",
    "    cv_scores.append(scores)\n",
    "\n",
    "# Display the cross-validation scores\n",
    "for i, kernel in enumerate(kernels):\n",
    "    print(f'Kernel: {kernel}, Cross-Validation Accuracy: {np.mean(cv_scores[i])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c06fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.89      0.94         9\n",
      "   virginica       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "\n",
      "Kernel: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "\n",
      "Kernel: poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.90      1.00      0.95         9\n",
      "   virginica       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define a function to train SVM model and evaluate performance\n",
    "def train_and_evaluate_svm_with_metrics(kernel, C=1.0, gamma='scale'):\n",
    "    # Initialize the SVM classifier\n",
    "    svm_classifier = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "    \n",
    "    # Train the SVM classifier\n",
    "    svm_classifier.fit(X_train_scaled, y_train_encoded)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = svm_classifier.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    report = classification_report(y_test_encoded, y_pred, target_names=iris_data.target_names)\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Evaluate SVM models with different kernels\n",
    "for kernel in kernels:\n",
    "    print(f\"Kernel: {kernel}\")\n",
    "    report = train_and_evaluate_svm_with_metrics(kernel)\n",
    "    print(report)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967cf46",
   "metadata": {},
   "source": [
    "Approach Documentation: Iris Dataset Classification with Support Vector Machines (SVM)\n",
    "\n",
    "1. Data Preprocessing Steps:\n",
    "\n",
    "Loading the Dataset: The dataset used for this task is the Iris dataset, a classic dataset in machine learning. It consists of 150 samples of iris flowers, with each sample containing four features: sepal length, sepal width, petal length, and petal width. The target variable is the species of iris, which can be one of three classes: setosa, versicolor, or virginica.\n",
    "Handling Missing Values: The Iris dataset is a clean dataset with no missing values, so no explicit handling of missing values is required.\n",
    "Scaling Features: The features are standardized using the StandardScaler from Scikit-learn to ensure that each feature contributes equally to the model's learning process.\n",
    "Encoding Categorical Variables: The target variable (species) is encoded using LabelEncoder from Scikit-learn to convert categorical labels into numerical values.\n",
    "2. SVM Model Configuration:\n",
    "\n",
    "Kernel Selection: We experiment with three common SVM kernels: linear, radial basis function (RBF), and polynomial.\n",
    "Model Training: The SVM models are trained using the SVC class from Scikit-learn. We specify the chosen kernel for each model.\n",
    "Model Evaluation: After training, the models are evaluated using various evaluation metrics such as accuracy, precision, recall, and F1-score.\n",
    "3. Cross-Validation Procedure:\n",
    "\n",
    "K-Fold Cross-Validation: We use K-fold cross-validation, a robust technique for model evaluation, to assess the performance of the SVM models.\n",
    "Number of Folds: We choose a suitable value for K, typically 5 or 10, to balance computational cost and reliability. In this case, we choose 5 folds.\n",
    "Shuffling: Before partitioning the dataset into folds, we shuffle the dataset to prevent any bias in the selection of folds.\n",
    "Cross-Validation Scores: We calculate the cross-validation accuracy for each SVM kernel configuration, providing a more reliable estimate of the model's performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "By following this approach, we preprocess the Iris dataset, configure SVM models with different kernels, and evaluate their performance using appropriate evaluation metrics and cross-validation techniques.\n",
    "This documentation provides clarity on the steps involved in the classification task, ensuring transparency and reproducibility of the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
